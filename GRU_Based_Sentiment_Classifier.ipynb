{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOP2CFVB12QDpEuKeruAnLF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deeksha-coder-debug/Stock-Prediction-project/blob/main/GRU_Based_Sentiment_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a GRU?\n",
        "GRU (Gated Recurrent Unit) is a variant of RNN that solves the vanishing gradient problem seen in traditional RNNs. It was introduced as a simpler alternative to LSTMs (Long Short-Term Memory networks). GRUs have two gates: an update gate and a reset gate. These gates help the model decide which information to keep and which to discard over time, allowing it to capture long-term dependencies efficiently without needing a separate memory cell (as used in LSTMs).\n",
        "\n",
        "Key Features of GRU:\n",
        "Update Gate: Controls how much of the previous information needs to be passed to the future.\n",
        "Reset Gate: Determines how much of the previous hidden state should be forgotten or reset.\n",
        "Simplified Structure: Unlike LSTMs, GRUs have fewer gates and fewer parameters, making them faster to train and less prone to overfitting on small datasets.\n",
        "GRU vs. LSTM:\n",
        "GRU: Simpler, fewer parameters, faster to train.\n",
        "LSTM: More flexible, slightly better at learning long-term dependencies.\n",
        "GRUs are often chosen when computational efficiency is a priority, especially for tasks like natural language processing."
      ],
      "metadata": {
        "id": "Vr2kAaZi-PoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import Required Libraries and Load IMDb Data"
      ],
      "metadata": {
        "id": "Le0DoN9QBt58"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CawPOP5K9fXV",
        "outputId": "5cca18c9-4b3c-4a38-d149-643143e1d82f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "# Preloaded IMDb movie review dataset with pre-tokenized reviews.\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# to ensure all reviews have the same length for feeding into the GRU.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Embedding, Dense\n",
        "# Recurrent neural network layer, similar to LSTM but slightly faster.\n",
        "# Converts integer word indices into dense word vectors (embeddings).\n",
        "\n",
        "# Parameters\n",
        "max_features = 10000  # Top 10,000 words\n",
        "maxlen = 500  # Maximum length of reviews (in terms of words)\n",
        "# GRU needs fixed-length sequences → ensures uniform input shape.\n",
        "embedding_size = 128\n",
        "\n",
        "# Load IMDb dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Pad Sequences\n",
        "The reviews in the dataset vary in length. For neural networks to process the data efficiently, all input sequences must be the same length. We achieve this by padding shorter sequences with zeros using the pad_sequences() function."
      ],
      "metadata": {
        "id": "iulS2ZeWBy9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pad sequences to the same length\n",
        "x_train=pad_sequences(x_train,maxlen=maxlen)\n",
        "x_test=pad_sequences(x_test,maxlen=maxlen)"
      ],
      "metadata": {
        "id": "diLKV8JdBmt5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By padding all sequences to the same length, the GRU will process each sequence as if it contains exactly 500 time steps, even though many reviews are shorter."
      ],
      "metadata": {
        "id": "WNCudYrqCFut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Build a GRU Model\n",
        "Now, let’s build the GRU-based model. We’ll start with an embedding layer to convert the integer word indices into dense vector representations. The GRU layer follows, which processes the input sequence. Finally, we add a dense layer with a sigmoid activation function to output a probability for binary classification (positive or negative sentiment)."
      ],
      "metadata": {
        "id": "KELjhh6JCQSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build GRU model\n",
        "model_gru=Sequential()\n",
        "model_gru.add(Embedding(max_features,embedding_size,input_length=maxlen))\n",
        "model_gru.add(GRU(64))  # Gru layer with 64 units\n",
        "model_gru.add(Dense(1,activation='sigmoid'))  # output layer for binary classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xSDH8geCBjm",
        "outputId": "d4c7d0ad-e291-4202-a65a-0ad34741638b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture Explained:\n",
        "\n",
        "* **Embedding Layer:** This layer converts word indices into dense vectors of fixed size (embedding_size=128). It allows the model to learn word representations during training.\n",
        "\n",
        "* ***GRU Layer:*** A single GRU layer with 64 units is used. The number of units controls the capacity of the GRU to learn from sequences. You can increase or decrease this value based on the complexity of the task and dataset.\n",
        "\n",
        "* **Dense Layer:** The dense layer with a sigmoid activation function outputs a single probability between 0 and 1, representing the sentiment (0 for negative, 1 for positive)."
      ],
      "metadata": {
        "id": "aRgfuL8YC6cq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Compile and Train the Model\n",
        "\n",
        "Next, we compile the model using the Adam optimizer and binary crossentropy loss function. The binary_crossentropy loss is used for binary classification tasks. We will also track the accuracy during training."
      ],
      "metadata": {
        "id": "EyUb0gsEDKw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model_gru.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# train model\n",
        "model_gru.fit(x_train,y_train,epochs=3,batch_size=64,validation_data=(x_test,y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxyx6FqgCuvg",
        "outputId": "f1dc74f8-efdc-46cc-cafa-e5e5af6de611"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.6583 - loss: 0.5918 - val_accuracy: 0.8447 - val_loss: 0.3651\n",
            "Epoch 2/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 31ms/step - accuracy: 0.8914 - loss: 0.2757 - val_accuracy: 0.8692 - val_loss: 0.3254\n",
            "Epoch 3/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - accuracy: 0.9280 - loss: 0.1931 - val_accuracy: 0.8743 - val_loss: 0.3352\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d91b6f1da90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer:** We use Adam as it is a popular choice for its adaptive learning rate and efficiency.\n",
        "\n",
        "**Loss Function:** Binary crossentropy is ideal for binary classification problems.\n",
        "\n",
        "**Metrics:** We track accuracy as the main evaluation metric."
      ],
      "metadata": {
        "id": "du6DyYMGDyNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training:\n",
        "\n",
        "**Epochs:** We train for 3 epochs. You can experiment with more epochs depending on the dataset and the computational resources available.\n",
        "\n",
        "**Batch Size**: A batch size of 64 is used. Larger batch sizes typically train faster but consume more memory."
      ],
      "metadata": {
        "id": "D65CjwO-ECmR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Evaluate the Model\n",
        "\n",
        "After training, we evaluate the model’s performance on the test dataset to check its accuracy."
      ],
      "metadata": {
        "id": "bXyq68dbEJkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "loss,accuracy=model_gru.evaluate(x_test,y_test)\n",
        "print(f'GRU Model test accuracy is {accuracy} and loss is {loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkMdjOiFDnEK",
        "outputId": "1ce343d2-0f7b-450b-fcff-29bdd3308803"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8731 - loss: 0.3416\n",
            "GRU Model test accuracy is 0.8743199706077576 and loss is 0.33519506454467773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Real-Time Text Sentiment Classification\n",
        "Now that the model is trained, we can use it to predict the sentiment of new movie reviews. We’ll preprocess the text reviews by tokenizing them into sequences of word indices, padding them to the same length as the training data, and passing them through the model for prediction."
      ],
      "metadata": {
        "id": "g4W_z97yEj7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Sample texts for real-time testing\n",
        "texts = [\n",
        "  \"I absolutely loved this movie, the storyline was engaging!\",\n",
        "  \"The film was too slow and boring for my taste.\",\n",
        "  \"A perfect blend of comedy and drama, truly enjoyable!\"\n",
        "]"
      ],
      "metadata": {
        "id": "bL0L0Q5TEYDj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Preprocess New Texts\n",
        "We need to convert the new texts into sequences of word indices using the same vocabulary as the IMDb dataset. We achieve this using the Tokenizer from Keras.\n",
        "\n",
        "The Tokenizer converts the input texts into sequences of word indices that match the format of the training data, and pad_sequences ensures that all sequences are of equal length."
      ],
      "metadata": {
        "id": "tOy7cQZ-FiJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "normally, when working with raw text data, the exact workflow is:\n",
        "\n",
        "**Raw text → Tokenizer → Fit → Word Index → Convert to Sequences → Pad → Model**\n",
        "\n",
        "But for the IMDb dataset, you must be very careful because Keras has already done part of this pipeline internally"
      ],
      "metadata": {
        "id": "qY9Lhs_BGHs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDb word index\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "\n",
        "# Tokenizer for IMDb dataset\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts([' '.join([str(word) for word in sequence]) for sequence in x_train])\n",
        "\n",
        "# Convert texts to sequences\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Pad the sequences\n",
        "padded_sequences = pad_sequences(sequences, maxlen=maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjj9sghNEp5u",
        "outputId": "273e014a-64da-4318-cf40-9d5e6cf154a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Make Predictions\n",
        "Finally, we pass the padded sequences to the trained GRU model to predict the sentiment of the texts."
      ],
      "metadata": {
        "id": "rWbmMla1GXP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict sentiment\n",
        "predictions=model_gru.predict(padded_sequences)\n",
        "\n",
        "# output the results\n",
        "for i,text in enumerate(texts):\n",
        "  sentiment='Positive' if predictions[i]>0.5 else 'Negative'\n",
        "  print(f'Text : {text}\\nPredicted Sentiment : {sentiment}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APpI0gi4GTDd",
        "outputId": "37330ad4-906b-4905-8a4c-28f358631ab5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Text : I absolutely loved this movie, the storyline was engaging!\n",
            "Predicted Sentiment : Negative\n",
            "\n",
            "Text : The film was too slow and boring for my taste.\n",
            "Predicted Sentiment : Negative\n",
            "\n",
            "Text : A perfect blend of comedy and drama, truly enjoyable!\n",
            "Predicted Sentiment : Negative\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x7-C0DcRG_RV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}